# AblationBench


> Can models help automate the design of ablation experiments in scientific papers? To explore this, we introduce **AblationBench**, a benchmark for evaluating models on ablation planning in empirical AI research. It includes two tasks: *AuthorAblation*, where the model proposes ablations from a method section, and *ReviewerAblation*, where it suggests missing ablations in a full paper. Across 83 papers in AuthorAblation and 350 papers in ReviewerAblation, we evaluate models using automatic LM-based judges and find that even the **best systems identify only 29% of ground-truth ablations**, highlighting how *challenging* and *open* this task remains.

<img src="_media/figure1.png" alt="fig1" width="400"/>

## Leaderboard


## AuthorAblation Task Instances


## ReviewerAblation Task Instances

