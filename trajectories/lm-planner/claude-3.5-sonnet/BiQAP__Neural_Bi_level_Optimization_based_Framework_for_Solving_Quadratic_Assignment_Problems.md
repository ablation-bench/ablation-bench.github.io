<style>
.trajectory-box strong {
  color: #1a1a1a !important;
}
.trajectory-box h3 {
  color: #1a1a1a !important;
}
</style>

# lm-planner/claude-3.5-sonnet/BiQAP__Neural_Bi_level_Optimization_based_Framework_for_Solving_Quadratic_Assignment_Problems

<div style="background: linear-gradient(135deg, #e3f2fd 0%, #bbdefb 100%); border-left: 5px solid #2196f3; padding: 20px; margin: 20px 0; border-radius: 8px; box-shadow: 0 2px 8px rgba(0,0,0,0.1); color: #1a1a1a;" class="trajectory-box">
<h2 style="color: #1976d2; margin-top: 0; margin-bottom: 15px; font-size: 1.3em;">ðŸ§  Reasoning Trace</h2>

Looking at the paper's methodology, I notice that the main components of BiQAP are:

1. The bi-level optimization framework with:
   - Outer optimization dealing with original QAP objective
   - Inner optimization using entropic regularization solved by Gromov-Sinkhorn algorithm

2. The FormulaNet architecture using Mamba for transforming QAP instances

The paper includes some ablations in Table 7 that test:
- Removing FormulaNet ("BiQAP w/o FN")
- Different numbers of outer/inner iterations (10/15, 20/25, 30/35)

However, I notice two important missing ablations:

1. The entropic regularization coefficient Îµ is a crucial hyperparameter that controls the trade-off between optimization and regularization in the inner optimization. The paper doesn't ablate its effect.

2. The paper uses Gumbel sampling for initialization but doesn't fully explore alternatives to this sampling strategy. While there are some sampling size experiments, they don't compare different sampling distributions/strategies.

I'll suggest these two as the most important missing ablations, ranked by importance.
</div>

<div style="background: linear-gradient(135deg, #e8f5e8 0%, #c8e6c9 100%); border-left: 5px solid #4caf50; padding: 20px; margin: 20px 0; border-radius: 8px; box-shadow: 0 2px 8px rgba(0,0,0,0.1); color: #1a1a1a;" class="trajectory-box">
<h2 style="color: #2e7d32; margin-top: 0; margin-bottom: 15px; font-size: 1.3em;">ðŸ“‹ Ablation Plan</h2>

### Entropic Regularization Ablation
- **Ablated Part**: entropic regularization coefficient Îµ in inner optimization
- **Action**: REPLACE
- **Replacement**: 
  - 0.01
  - 0.1
  - 1.0
  - 10.0
- **Metrics**: obj, gap, time(sec/100it), acc(%)

### Initialization Strategy Ablation
- **Ablated Part**: Gumbel sampling initialization strategy
- **Action**: REPLACE
- **Replacement**: 
  - uniform random
  - normal distribution
  - learned initialization
- **Metrics**: obj, gap, time(sec/100it), acc(%)

</div>