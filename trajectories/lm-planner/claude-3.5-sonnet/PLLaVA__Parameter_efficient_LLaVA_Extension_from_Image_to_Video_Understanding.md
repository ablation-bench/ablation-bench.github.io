<style>
.trajectory-box strong {
  color: #1a1a1a !important;
}
.trajectory-box h3 {
  color: #1a1a1a !important;
}
</style>

# lm-planner/claude-3.5-sonnet/PLLaVA__Parameter_efficient_LLaVA_Extension_from_Image_to_Video_Understanding

<div style="background: linear-gradient(135deg, #e3f2fd 0%, #bbdefb 100%); border-left: 5px solid #2196f3; padding: 20px; margin: 20px 0; border-radius: 8px; box-shadow: 0 2px 8px rgba(0,0,0,0.1); color: #1a1a1a;" class="trajectory-box">
<h2 style="color: #1976d2; margin-top: 0; margin-bottom: 15px; font-size: 1.3em;">ðŸ§  Reasoning Trace</h2>

The paper presents PLLaVA, a method for adapting image-language models to video understanding using pooling strategies. From analyzing the paper, I notice that while there are some ablation studies on:

1. Spatial vs temporal pooling dimensions and ratios (Section 4.2)
2. Post-optimization fusion ratio Î± (Section 4.4)

However, there are some important aspects that lack ablation analysis:

1. The choice of input frame sampling strategy is not thoroughly investigated. While they use 16 uniformly sampled frames, there's no analysis of how different frame sampling approaches affect performance.

2. The paper uses a fixed pooling shape of 16x12x12xd but doesn't fully justify this specific configuration beyond some basic experiments. A more systematic ablation of different pooling architectures could be valuable.

These missing ablations would help better understand the method's key components and design choices.

Based on the metrics used in the paper (VCG Score, MVBench accuracy, VideoQA accuracy), I'll suggest ablation studies for these two aspects.
</div>

<div style="background: linear-gradient(135deg, #e8f5e8 0%, #c8e6c9 100%); border-left: 5px solid #4caf50; padding: 20px; margin: 20px 0; border-radius: 8px; box-shadow: 0 2px 8px rgba(0,0,0,0.1); color: #1a1a1a;" class="trajectory-box">
<h2 style="color: #2e7d32; margin-top: 0; margin-bottom: 15px; font-size: 1.3em;">ðŸ“‹ Ablation Plan</h2>

### Frame Sampling Strategy Ablation
- **Ablated Part**: Video frame sampling method
- **Action**: REPLACE
- **Replacement**: 
  - uniform sampling
  - dense sampling
  - keyframe-based sampling
- **Metrics**: VCG Score, MVBench accuracy, VideoQA accuracy

### Pooling Architecture Ablation
- **Ablated Part**: Pooling layer configuration
- **Action**: REPLACE
- **Replacement**: 
  - 8x8x8xd
  - 16x8x8xd
  - 16x16x16xd
  - 32x12x12xd
- **Metrics**: VCG Score, MVBench accuracy, VideoQA accuracy

</div>