<style>
.trajectory-box strong {
  color: #1a1a1a !important;
}
.trajectory-box h3 {
  color: #1a1a1a !important;
}
</style>

# lm-planner/gpt-4o/On_Pre_training_Language_Model_for_Antibody

<div style="background: linear-gradient(135deg, #e3f2fd 0%, #bbdefb 100%); border-left: 5px solid #2196f3; padding: 20px; margin: 20px 0; border-radius: 8px; box-shadow: 0 2px 8px rgba(0,0,0,0.1); color: #1a1a1a;" class="trajectory-box">
<h2 style="color: #1976d2; margin-top: 0; margin-bottom: 15px; font-size: 1.3em;">ðŸ§  Reasoning Trace</h2>

The paper "On Pre-training Language Model for Antibody" explores the representation capabilities of pre-trained language models on antibody tasks. It introduces the AnTibody Understanding Evaluation (ATUE) benchmark and evaluates various models, including ESM, AntiBERT, and EATLM, on tasks with different antibody specificity levels. The paper also incorporates biological mechanisms into pre-training to enhance model performance.

The existing ablation studies in the paper focus on the impact of removing specific pre-training objectives, such as Ancestor Germline Prediction (AGP) and Mutation Position Prediction (MPP), on the EATLM model's performance. These studies highlight the importance of these objectives in capturing evolutionary relationships and mutation specificity.

However, the paper does not explore the impact of different pre-training datasets on model performance. Given the importance of data diversity and quality in pre-training, an ablation study that investigates the effect of using different datasets could provide valuable insights. Additionally, the paper does not examine the impact of varying the architecture of the pre-trained models, such as the number of layers or hidden units, which could also influence performance.

Therefore, I suggest two missing ablation studies: one focusing on the pre-training dataset and another on the model architecture. These studies will help understand the contribution of data and architecture to the model's performance on antibody tasks.
</div>

<div style="background: linear-gradient(135deg, #e8f5e8 0%, #c8e6c9 100%); border-left: 5px solid #4caf50; padding: 20px; margin: 20px 0; border-radius: 8px; box-shadow: 0 2px 8px rgba(0,0,0,0.1); color: #1a1a1a;" class="trajectory-box">
<h2 style="color: #2e7d32; margin-top: 0; margin-bottom: 15px; font-size: 1.3em;">ðŸ“‹ Ablation Plan</h2>

### Dataset Ablation
- **Ablated Part**: pre-training dataset
- **Action**: REPLACE
- **Replacement**: 
  - OAS subset
  - UniRef50
  - random protein sequences
- **Metrics**: AUC, F1, MCC, ACC

### Architecture Ablation
- **Ablated Part**: model architecture
- **Action**: REPLACE
- **Replacement**: 
  - 6 layers
  - 24 layers
  - 1024 hidden units
- **Metrics**: AUC, F1, MCC, ACC

</div>