<style>
.trajectory-box strong {
  color: #1a1a1a !important;
}
.trajectory-box h3 {
  color: #1a1a1a !important;
}
</style>

# lm-planner/gpt-4o/Finetuning_CLIP_to_Reason_about_Pairwise_Differences

<div style="background: linear-gradient(135deg, #e3f2fd 0%, #bbdefb 100%); border-left: 5px solid #2196f3; padding: 20px; margin: 20px 0; border-radius: 8px; box-shadow: 0 2px 8px rgba(0,0,0,0.1); color: #1a1a1a;" class="trajectory-box">
<h2 style="color: #1976d2; margin-top: 0; margin-bottom: 15px; font-size: 1.3em;">ðŸ§  Reasoning Trace</h2>

The paper "Finetuning CLIP to Reason about Pairwise Differences" introduces a method to enhance CLIP's ability to reason about differences in embedding space by aligning image differences with text descriptions generated by large language models (LLMs). The paper includes several ablation studies, such as the impact of filtering LLM-generated data and the use of different datasets for finetuning. However, there are some potential areas for further ablation studies that could provide additional insights into the method's performance.

One missing ablation study could involve the impact of different types of LLMs used for generating text descriptions of image differences. The paper uses LLaMA2-13B-chat-hf for generating these descriptions, but it would be valuable to explore how the choice of LLM affects the performance of the finetuned model. This could help determine if the improvements are specific to the LLM used or if they generalize across different LLMs.

Another potential ablation study could focus on the impact of the contrastive loss function used during finetuning. The paper primarily uses the original CLIP contrastive loss but also mentions the use of squared loss in the appendix. A more detailed ablation study comparing different loss functions could provide insights into how the choice of loss function affects the alignment of image and text embeddings and the overall performance of the model.

These ablation studies would help attribute the method's performance to its major components and provide a deeper understanding of the factors contributing to the improvements observed in the paper.
</div>

<div style="background: linear-gradient(135deg, #e8f5e8 0%, #c8e6c9 100%); border-left: 5px solid #4caf50; padding: 20px; margin: 20px 0; border-radius: 8px; box-shadow: 0 2px 8px rgba(0,0,0,0.1); color: #1a1a1a;" class="trajectory-box">
<h2 style="color: #2e7d32; margin-top: 0; margin-bottom: 15px; font-size: 1.3em;">ðŸ“‹ Ablation Plan</h2>

### Ablation Study on LLM Choice
- **Ablated Part**: LLM used for generating text descriptions of image differences
- **Action**: REPLACE
- **Replacement**: 
  - GPT-3
  - BERT
  - T5
- **Metrics**: difference-based classification accuracy, zeroshot classification accuracy, CLIP-Score

### Ablation Study on Loss Function
- **Ablated Part**: Loss function used during finetuning
- **Action**: REPLACE
- **Replacement**: 
  - contrastive loss
  - squared loss
  - hinge loss
- **Metrics**: difference-based classification accuracy, zeroshot classification accuracy, CLIP-Score

</div>