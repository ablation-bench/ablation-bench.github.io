<style>
.trajectory-box strong {
  color: #1a1a1a !important;
}
.trajectory-box h3 {
  color: #1a1a1a !important;
}
</style>

# lm-planner/gemini-2.5-flash/Explaining_black_box_text_modules_in_natural_language_with_language_models

<div style="background: linear-gradient(135deg, #e3f2fd 0%, #bbdefb 100%); border-left: 5px solid #2196f3; padding: 20px; margin: 20px 0; border-radius: 8px; box-shadow: 0 2px 8px rgba(0,0,0,0.1); color: #1a1a1a;" class="trajectory-box">
<h2 style="color: #1976d2; margin-top: 0; margin-bottom: 15px; font-size: 1.3em;">ðŸ§  Reasoning Trace</h2>

The paper "Explaining black box text modules in natural language with language models" introduces SASC, a two-step method for generating natural language explanations for text modules. The method involves a summarization step where a helper LLM summarizes top-activating ngrams into candidate explanations, and a synthetic scoring step where the helper LLM generates synthetic text based on candidates to evaluate their reliability using an explanation score.

The paper includes several ablation studies and comparisons:
1.  **Impact of Corpus and Noise:** Evaluates SASC performance on synthetic modules under different conditions (Default, Restricted corpus, Noisy module), showing robustness to corpus choice and noise (Table 1).
2.  **Impact of Ngram Length and Helper LLM:** Explores varying ngram lengths (bigrams, trigrams, 4-grams) and using a different helper LLM (LLaMA-2 instead of GPT-3), showing similar performance across these variations (Table 2, Fig A1).
3.  **Comparison to Baselines:** Compares SASC to ngram summarization (SASC without the scoring step), gradient-based methods, and topic modeling, demonstrating the value of the full SASC pipeline, particularly the scoring step (Table 1, Table 2).

While these experiments cover important aspects like the helper LLM choice, ngram length, and the overall importance of the scoring step, there are a couple of key areas that could benefit from further investigation through ablation studies:

1.  **The Synthetic Scoring Mechanism:** The scoring step is crucial for SASC's performance over the baseline. This step relies on the helper LLM to generate both text related to the explanation (`Text+`) and text *not* related to the explanation (`Text-`). The paper notes that improper generation of `Text-` could introduce bias and suggests using a large set of neutral texts from a generic corpus as an alternative for `Text-`. An ablation study comparing the original LLM-based `Text-` generation with using a generic corpus would directly assess the impact and potential bias of the LLM's negative generation capability on the explanation score and overall performance. This is a critical part of the scoring mechanism that hasn't been directly ablated.
2.  **Sensitivity to Key Hyperparameters:** The method uses fixed numbers for selecting ngrams (30 random from top 50) and generating candidate explanations (5 candidates). While some hyperparameters (ngram length, LLM model) were varied, the sensitivity to the *number* of ngrams used for summarization or the *number* of candidate explanations generated is not explicitly shown. These choices can impact both performance (e.g., more candidates might yield a better one) and computational cost. An ablation on the number of candidate explanations would be a standard and informative analysis of the method's robustness and efficiency trade-offs.

Based on their importance to the core mechanism (scoring) and standard practice (hyperparameter sensitivity), I propose the following two missing ablation studies.
</div>

<div style="background: linear-gradient(135deg, #e8f5e8 0%, #c8e6c9 100%); border-left: 5px solid #4caf50; padding: 20px; margin: 20px 0; border-radius: 8px; box-shadow: 0 2px 8px rgba(0,0,0,0.1); color: #1a1a1a;" class="trajectory-box">
<h2 style="color: #2e7d32; margin-top: 0; margin-bottom: 15px; font-size: 1.3em;">ðŸ“‹ Ablation Plan</h2>

### Scoring Negative Text Source
- **Ablated Part**: Source of unrelated/negative synthetic text used in the explanation scoring step.
- **Action**: REPLACE
- **Replacement**: 
  - LLM-generated 'not similar' text (original)
  - Text sampled from a generic corpus
- **Metrics**: Accuracy, BERT Score, Explanation score

### Number of Explanation Candidates
- **Ablated Part**: Number of candidate explanations generated by the helper LLM in the summarization step.
- **Action**: REPLACE
- **Replacement**: 
  - 1
  - 3
  - 5
  - 10
- **Metrics**: Accuracy, BERT Score

</div>