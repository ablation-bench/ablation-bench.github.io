<style>
.trajectory-box strong {
  color: #1a1a1a !important;
}
.trajectory-box h3 {
  color: #1a1a1a !important;
}
</style>

# lm-planner/gemini-2.5-flash/Unlocking_the_Power_of_Representations_in_Long_term_Novelty_based_Exploration

<div style="background: linear-gradient(135deg, #e3f2fd 0%, #bbdefb 100%); border-left: 5px solid #2196f3; padding: 20px; margin: 20px 0; border-radius: 8px; box-shadow: 0 2px 8px rgba(0,0,0,0.1); color: #1a1a1a;" class="trajectory-box">
<h2 style="color: #1976d2; margin-top: 0; margin-bottom: 15px; font-size: 1.3em;">ðŸ§  Reasoning Trace</h2>

The user requested up to two missing ablation studies for the paper "Unlocking the Power of Representations in Long-term Novelty-based Exploration". I analyzed the paper, focusing on the proposed methods RECODE and CASM, and the ablation studies already presented in Section 5.3 and Appendix L.

RECODE is a non-parametric method for novelty-based exploration using clustering-based online density estimation. Its key components include a memory of atoms (cluster centroids) and counts, a soft-visitation count estimation based on a kernel and distance threshold, and memory update rules involving atom insertion and removal with count decay. The paper ablates the atom removal strategy, the count discount factor (Î³), memory size, and insertion probability (Î·). It also compares RECODE against other exploration methods (NGU, EMM, RND) and shows its robustness to noise.

CASM is a representation learning method using a masked transformer architecture. It takes masked sequences of actions and embedded observations and is trained to reconstruct missing embeddings and predict the 1-step action. The paper ablates the masking strategy itself (CASnotM) and compares CASM embeddings against AP embeddings for both RECODE and NGU.

Based on this analysis, I identified two important aspects of the method that were not thoroughly ablated:

1.  **RECODE's Kernel Function and Distance Metric:** The paper uses a specific kernel function (Eq. 3) with an L2 distance and a distance threshold (`d_ema`). While the paper justifies using a distance threshold over k-nearest neighbors with counts, it does not explore alternative kernel functions (e.g., standard RBF/Gaussian) or distance metrics (e.g., cosine similarity, L1 distance) which are fundamental to how similarity and density are computed in the embedding space. An ablation here would assess the sensitivity of RECODE's performance to this core design choice.
2.  **CASM's Prediction Task:** CASM learns representations by training a transformer on masked sequences to reconstruct masked embeddings and predict the 1-step action. The paper shows the importance of the masking strategy and the CASM architecture compared to simpler AP embeddings. However, the specific *targets* of the prediction task (reconstructing embeddings, predicting 1-step action) are not varied. Different prediction tasks could lead to representations that capture different aspects of the environment dynamics or state structure. Ablating the prediction targets would help understand which specific predictive signals are crucial for learning representations effective for exploration with RECODE.

Both ablations are important for understanding the contributions of RECODE and CASM, respectively. I decided to rank the CASM Prediction Target Ablation slightly higher as it probes the core mechanism by which CASM learns its representation, which is a significant part of the paper's contribution alongside RECODE itself.

For the RECODE Kernel Function ablation, I propose replacing the current kernel with a standard RBF kernel, which is a common alternative for density estimation based on distances. For the CASM Prediction Target ablation, I propose replacing the current targets with predicting the *next* embedding and predicting a *future* action (e.g., 5 steps ahead), as these are common alternative self-supervised tasks for representation learning in sequential data.

The metrics used for these ablations should align with those used in the paper, primarily Human Normalized Score (HNS) and potentially Area Under the Curve (AUC) for Atari, and HNS for DM-HARD-8.
</div>

<div style="background: linear-gradient(135deg, #e8f5e8 0%, #c8e6c9 100%); border-left: 5px solid #4caf50; padding: 20px; margin: 20px 0; border-radius: 8px; box-shadow: 0 2px 8px rgba(0,0,0,0.1); color: #1a1a1a;" class="trajectory-box">
<h2 style="color: #2e7d32; margin-top: 0; margin-bottom: 15px; font-size: 1.3em;">ðŸ“‹ Ablation Plan</h2>

### CASM Prediction Target Ablation
- **Ablated Part**: The specific prediction targets used in the CASM representation learning loss (reconstructing masked embeddings and predicting 1-step action).
- **Action**: REPLACE
- **Replacement**: 
  - Predict next embedding
  - Predict future action (e.g., 5 steps ahead)
- **Metrics**: Human Normalized Score, Area Under the Curve

### RECODE Kernel Function Ablation
- **Ablated Part**: The kernel function and distance metric used for calculating soft-visitation counts and updating memory atoms in RECODE.
- **Action**: REPLACE
- **Replacement**: 
  - Standard RBF kernel (exp(-d^2 / (2*sigma^2)))
  - Cosine similarity based kernel
- **Metrics**: Human Normalized Score, Area Under the Curve

</div>