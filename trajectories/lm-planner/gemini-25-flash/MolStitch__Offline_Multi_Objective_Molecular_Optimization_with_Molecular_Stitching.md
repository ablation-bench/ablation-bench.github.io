<style>
.trajectory-box strong {
  color: #1a1a1a !important;
}
.trajectory-box h3 {
  color: #1a1a1a !important;
}
</style>

# lm-planner/gemini-2.5-flash/MolStitch__Offline_Multi_Objective_Molecular_Optimization_with_Molecular_Stitching

<div style="background: linear-gradient(135deg, #e3f2fd 0%, #bbdefb 100%); border-left: 5px solid #2196f3; padding: 20px; margin: 20px 0; border-radius: 8px; box-shadow: 0 2px 8px rgba(0,0,0,0.1); color: #1a1a1a;" class="trajectory-box">
<h2 style="color: #1976d2; margin-top: 0; margin-bottom: 15px; font-size: 1.3em;">ðŸ§  Reasoning Trace</h2>

The paper "MolStitch: Offline Multi-Objective Molecular Optimization with Molecular Stitching" proposes a novel framework for offline multi-objective molecular optimization. The core idea is to leverage an offline dataset to train a generative model by creating synthetic "stitched molecules" that combine desirable properties from existing molecules. The framework consists of several key components: a generative model (fine-tuned), StitchNet (for generating stitched molecules), a rank-based proxy model (for evaluating stitched molecules), and priority sampling (for selecting diverse molecule pairs for stitching). The generative model is fine-tuned using a preference optimization technique based on the proxy's evaluations.

The paper includes an ablation study in Section 5.2 (Table 3) that investigates the impact of the Rank-based Proxy (RP), StitchNet (SN), and Priority Sampling (PS). It shows that the full MolStitch (RP âœ”, SN âœ”, PS âœ”) performs best. Appendix L provides a detailed comparison of the rank-based proxy versus a score-based proxy. Appendix M explores using multiple proxies. Appendix N analyzes the diversity of molecules generated by StitchNet. Appendix P assesses StitchNet's ability to learn crossover. Appendix Q evaluates the quality of stitched molecules. Appendix R discusses reward hacking and PS. Appendix S explores integrating BO techniques.

While the existing ablations cover the *presence* of the main components (RP, SN, PS) and compare different *types* of proxies (rank vs score) and *types* of data augmentation (StitchNet vs others) and *types* of preference optimization, there are still important aspects of the method's design choices that could be further investigated through ablation.

Two important missing ablation studies are identified:

1.  **StitchNet Training Process:** StitchNet undergoes two training stages: unsupervised pre-training on ZINC using a rule-based crossover operator to learn chemical grammar, and self-supervised training using chemical feedback derived from the original molecule's objective scores (if the stitched molecule is sufficiently similar). The existing ablation (Table 3, SN âœ” vs SN -) compares having StitchNet (presumably with both training stages) versus not having it (implicitly using another data augmentation like stochastic sampling). A missing ablation is to specifically evaluate the contribution of the *self-supervised training* stage of StitchNet. Does learning from the approximated chemical feedback significantly improve performance compared to a StitchNet that is only pre-trained on chemical grammar/crossover rules? This would isolate the impact of the novel self-supervised training approach.

2.  **Priority Sampling Parameter Sensitivity:** Priority Sampling uses a Dirichlet distribution with a concentration parameter Î± to generate diverse weight configurations for selecting molecule pairs for StitchNet. The paper states that PS is crucial for exploring complex Pareto fronts, especially with more objectives (Section 5.2). However, the ablation study only compares having PS versus not having it (implicitly using uniform sampling or fixed weights). It does not investigate the sensitivity of the method's performance to the value of the concentration parameter Î±. Different values of Î± lead to different distributions of weights (e.g., sparse vs uniform), which would affect the diversity of molecule pairs sampled and thus the stitched molecules. An ablation varying Î± would provide insight into how the nature of priority sampling impacts the optimization process.

These two ablations are important because they probe specific, non-trivial design choices within two of the method's core novel components (StitchNet and Priority Sampling) that are not fully explained by the existing ablations. They would help attribute the performance gains more precisely to these specific mechanisms.

The metrics used in the main ablation study (Table 3) are Hypervolume (HV) and R2 indicator (R2). These are appropriate metrics for multi-objective optimization and should be used for the suggested ablations for consistency.
</div>

<div style="background: linear-gradient(135deg, #e8f5e8 0%, #c8e6c9 100%); border-left: 5px solid #4caf50; padding: 20px; margin: 20px 0; border-radius: 8px; box-shadow: 0 2px 8px rgba(0,0,0,0.1); color: #1a1a1a;" class="trajectory-box">
<h2 style="color: #2e7d32; margin-top: 0; margin-bottom: 15px; font-size: 1.3em;">ðŸ“‹ Ablation Plan</h2>

### Ablate StitchNet Self-Supervised Training
- **Ablated Part**: StitchNet's self-supervised training process using chemical feedback
- **Action**: REMOVE
- **Metrics**: HV, R2

### Priority Sampling Alpha Sensitivity
- **Ablated Part**: Concentration parameter (Î±) of the Dirichlet distribution for Priority Sampling
- **Action**: REPLACE
- **Replacement**: 
  - 0.1
  - 1.0
  - 10.0
- **Metrics**: HV, R2

</div>