<style>
.trajectory-box strong {
  color: #1a1a1a !important;
}
.trajectory-box h3 {
  color: #1a1a1a !important;
}
</style>

# lm-planner/gemini-2.5-flash/Self_RAG__Learning_to_Retrieve__Generate__and_Critique_through_Self_Reflection

<div style="background: linear-gradient(135deg, #e3f2fd 0%, #bbdefb 100%); border-left: 5px solid #2196f3; padding: 20px; margin: 20px 0; border-radius: 8px; box-shadow: 0 2px 8px rgba(0,0,0,0.1); color: #1a1a1a;" class="trajectory-box">
<h2 style="color: #1976d2; margin-top: 0; margin-bottom: 15px; font-size: 1.3em;">ðŸ§  Reasoning Trace</h2>

The user requested up to two missing ablation studies for the Self-RAG paper. I have analyzed the paper, focusing on the method described in Section 3 and the existing ablation studies presented in Section 5.2.

The Self-RAG framework introduces several key components:
1.  **Reflection Tokens:** Special tokens (`Retrieve`, `ISREL`, `ISSUP`, `ISUSE`) generated by the LM to guide the process.
2.  **Critic Model (C):** Trained to predict reflection tokens based on GPT-4 supervision, used to create training data for the generator.
3.  **Generator Model (M):** Trained end-to-end to generate text and reflection tokens, using data augmented by the retriever and critic.
4.  **Retriever (R):** Used on-demand when the generator predicts `Retrieve=Yes`.
5.  **Inference Strategy:** Segment-level beam search guided by a weighted sum of critique token probabilities, with adaptive retrieval based on a threshold.

The existing ablation studies in Section 5.2 investigate:
*   Training without the retriever (`No Retriever`).
*   Training without the critic/reflection tokens (`No Critic`).
*   Inference without retrieval (`No retrieval`).
*   Inference with hard retrieval constraints (`Hard constraints`).
*   Inference always retrieving only the top-1 document (`Retrieve top 1`).
*   Inference beam search without the `ISSUP` score (`Remove ISSUP`).

Based on this analysis, I identified two important aspects that are not fully explored by the existing ablations:

1.  **Contribution of Individual Reflection Token Types during Training:** The `No Critic` ablation shows that training with *some* reflection tokens is beneficial compared to standard RAG training. However, Self-RAG uses four distinct types of reflection tokens (`Retrieve`, `ISREL`, `ISSUP`, `ISUSE`). The existing ablations do not isolate the contribution of learning to predict each *specific* type of token during the generator's training phase. Understanding which reflection types are most crucial for the performance gains would provide valuable insights into the mechanism of Self-RAG. This is a fundamental missing piece in the training ablation analysis.

2.  **Systematic Variation of the Number of Retrieved Passages (K) at Inference:** The paper uses a default number of retrieved passages (K=5 or 10) when retrieval is triggered and includes an ablation for K=1 (`Retrieve top 1`). However, a more systematic study varying K across a range of values (e.g., 1, 3, 5, 10) during inference would better illustrate the trade-off between performance and computational cost associated with retrieval scale within the Self-RAG framework. This is a standard hyperparameter in RAG systems, and its impact within the adaptive, self-reflective framework is important to quantify more thoroughly.

These two ablations are important because they probe the core components of Self-RAG (the specific types of reflection signals learned) and a key practical hyperparameter (retrieval scale at inference) in more detail than the existing studies. I will propose these two, ranked by importance (individual token contribution during training being slightly more fundamental to the method's novelty).

The metrics used in the existing ablations are PopQA (acc), PubHealth (acc), and ASQA (citation precision). The main results table (Table 2) provides a broader set of metrics for these tasks (PopQA acc, PubHealth acc, ASQA em, rg, mau, prec, rec). I will include accuracy for PopQA and PubHealth, and precision, recall, and MAUVE for ASQA, as these cover correctness, factuality, and fluency, which are key claims of the paper.
</div>

<div style="background: linear-gradient(135deg, #e8f5e8 0%, #c8e6c9 100%); border-left: 5px solid #4caf50; padding: 20px; margin: 20px 0; border-radius: 8px; box-shadow: 0 2px 8px rgba(0,0,0,0.1); color: #1a1a1a;" class="trajectory-box">
<h2 style="color: #2e7d32; margin-top: 0; margin-bottom: 15px; font-size: 1.3em;">ðŸ“‹ Ablation Plan</h2>

### Ablate Reflection Token Training
- **Ablated Part**: Training signal for specific reflection token types (Retrieve, ISREL, ISSUP, ISUSE) in the generator model
- **Action**: REMOVE
- **Metrics**: PopQA (acc), PubHealth (acc), ASQA (prec), ASQA (rec), ASQA (mau)

### Vary Inference Retrieval K
- **Ablated Part**: Number of retrieved passages (K) used during inference when retrieval is triggered
- **Action**: REPLACE
- **Replacement**: 
  - 1
  - 3
  - 5
  - 10
- **Metrics**: PopQA (acc), PubHealth (acc), ASQA (prec), ASQA (rec), ASQA (mau)

</div>