<style>
.trajectory-box strong {
  color: #1a1a1a !important;
}
.trajectory-box h3 {
  color: #1a1a1a !important;
}
</style>

# lm-planner/gemini-2.5-flash/Evolving_Alignment_via_Asymmetric_Self_Play

<div style="background: linear-gradient(135deg, #e3f2fd 0%, #bbdefb 100%); border-left: 5px solid #2196f3; padding: 20px; margin: 20px 0; border-radius: 8px; box-shadow: 0 2px 8px rgba(0,0,0,0.1); color: #1a1a1a;" class="trajectory-box">
<h2 style="color: #1976d2; margin-top: 0; margin-bottom: 15px; font-size: 1.3em;">ðŸ§  Reasoning Trace</h2>

The paper "Evolving Alignment via Asymmetric Self-Play (eva)" introduces a novel framework for aligning language models by casting it as an asymmetric game between a creator policy that generates prompts and a solver policy that generates responses. The core idea is that the creator evolves the prompt distribution to challenge the solver, leading to improved generalization. The method involves an iterative process where the creator estimates prompt informativeness based on the current solver, samples an informative subset, evolves new prompts from this subset, mixes them with original prompts, and then the solver trains on this new distribution.

The paper includes several ablation studies investigating key aspects of the method:
1.  **Informativeness Metric:** Comparing different ways to quantify prompt informativeness (e.g., advantage-based vs. variance-based).
2.  **Sample-then-Evolve Procedure:** Analyzing the importance of the prompt evolution step and the sampling strategy (weighted sampling vs. greedy selection).
3.  **Scaling with Reward Models:** Demonstrating that performance improves with higher quality reward models used as the preference oracle.
4.  **Continual Training:** Showing performance gains over multiple iterations of the eva process.
5.  **Different Evolve Methods:** Testing different prompt generation models/strategies for the 'evolve' step.
6.  **Adding Rewriter:** Exploring enhancements to the solver's response generation.
7.  **Curriculum Visualization:** Providing empirical evidence of the evolved prompt distribution and its characteristics (complexity, topic shifts).

Based on the method description and the existing ablations, two important hyperparameters/design choices that significantly influence the data distribution and the learning process, but have not been thoroughly ablated, are:

1.  **The ratio of newly evolved prompts mixed with the original prompt buffer:** The paper mentions mixing 80% evolved prompts with 20% original prompts in Appendix A but states that extensive parameter search was not performed for this ratio. This ratio directly controls the balance between exploring novel, challenging prompts generated by the creator and maintaining diversity or stability from the initial data distribution. Ablating this parameter would reveal the sensitivity of eva's performance to this mixing strategy and help understand the contribution of the original data buffer.
2.  **The number of responses sampled per prompt in the solver step:** To calculate the informativeness metric and generate preference pairs (y+, y-), the method samples multiple responses (default 6) from the current solver policy for each prompt. The number of samples affects the reliability of the informativeness estimate and the quality of the preference pairs used for training. Sampling too few might lead to noisy signals, while sampling too many increases computational cost. Ablating this parameter would assess the trade-off between computational efficiency and the quality of the generated training data and informativeness signal.

These two ablations are crucial for understanding the robustness and efficiency of the data generation and curriculum learning aspects of eva, which are central to its novelty. They are distinct from the existing ablations which focus on the *type* of informativeness metric, the *procedure* of evolving, the *quality* of the reward model, or the *number of iterations*.
</div>

<div style="background: linear-gradient(135deg, #e8f5e8 0%, #c8e6c9 100%); border-left: 5px solid #4caf50; padding: 20px; margin: 20px 0; border-radius: 8px; box-shadow: 0 2px 8px rgba(0,0,0,0.1); color: #1a1a1a;" class="trajectory-box">
<h2 style="color: #2e7d32; margin-top: 0; margin-bottom: 15px; font-size: 1.3em;">ðŸ“‹ Ablation Plan</h2>

### Evolved vs Original Prompt Ratio
- **Ablated Part**: The ratio of newly evolved prompts to original prompts mixed in the training dataset for each iteration.
- **Action**: REPLACE
- **Replacement**: 
  - 1.0
  - 0.8
  - 0.5
  - 0.2
  - 0.0
- **Metrics**: WR (%) Arena-Hard, avg. score MT-Bench, 1st turn MT-Bench, 2nd turn MT-Bench, LC-WR (%) AlpacaEval 2.0, WR (%) AlpacaEval 2.0

### Responses per Prompt
- **Ablated Part**: The number of responses sampled from the solver policy for each prompt to calculate informativeness and generate preference pairs.
- **Action**: REPLACE
- **Replacement**: 
  - 2
  - 4
  - 6
  - 8
  - 10
- **Metrics**: WR (%) Arena-Hard, avg. score MT-Bench, 1st turn MT-Bench, 2nd turn MT-Bench, LC-WR (%) AlpacaEval 2.0, WR (%) AlpacaEval 2.0

</div>