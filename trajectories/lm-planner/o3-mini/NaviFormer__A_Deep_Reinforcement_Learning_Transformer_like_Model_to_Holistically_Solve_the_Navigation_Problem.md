<style>
.trajectory-box strong {
  color: #1a1a1a !important;
}
.trajectory-box h3 {
  color: #1a1a1a !important;
}
</style>

# lm-planner/o3-mini/NaviFormer__A_Deep_Reinforcement_Learning_Transformer_like_Model_to_Holistically_Solve_the_Navigation_Problem

<div style="background: linear-gradient(135deg, #e3f2fd 0%, #bbdefb 100%); border-left: 5px solid #2196f3; padding: 20px; margin: 20px 0; border-radius: 8px; box-shadow: 0 2px 8px rgba(0,0,0,0.1); color: #1a1a1a;" class="trajectory-box">
<h2 style="color: #1976d2; margin-top: 0; margin-bottom: 15px; font-size: 1.3em;">üß† Reasoning Trace</h2>

The NaviFormer paper already provides an extensive set of ablation studies on its core modules (encoder design with combined attention, various configurations in the direction prediction module using different choices of convolutional and linear layers, and the comparison with a two-step planning approach). However, two important aspects were not ablated. First, while the paper uses a discrete action space of four motion actions in the direction prediction module ‚Äì which directly affects both the success rate (through safe depot arrivals) and the node visitation rate ‚Äì there is no study on how a more granular or even continuous action space might impact overall performance. This is particularly relevant as the authors themselves mention that ‚Äúfuture research may focus on improving direction prediction for more motion actions or continuous directions‚Äù. Assessing the trade-offs between using 4, 8, or a continuous action space would offer insights into the optimal balance between safety, exploration (node rate), and computational cost. Second, the encoder architecture is based on stacking N=3 attention blocks. Although the combined multi-head attention mechanism is a key component of NaviFormer, the sensitivity of performance (in terms of both success and node rates) and computation time to the depth of this module has not been analyzed. An ablation study that varies the number of encoder layers (e.g., 1, 2, 3, and 4 layers) could provide valuable insights into whether additional layers help in capturing the intricate relationships between nodes and obstacles or if they add unnecessary computational overhead.
</div>

<div style="background: linear-gradient(135deg, #e8f5e8 0%, #c8e6c9 100%); border-left: 5px solid #4caf50; padding: 20px; margin: 20px 0; border-radius: 8px; box-shadow: 0 2px 8px rgba(0,0,0,0.1); color: #1a1a1a;" class="trajectory-box">
<h2 style="color: #2e7d32; margin-top: 0; margin-bottom: 15px; font-size: 1.3em;">üìã Ablation Plan</h2>

### Motion Action Granularity Ablation
- **Ablated Part**: Direction prediction module's discretization of motion actions (currently using 4 discrete actions for motion control)
- **Action**: REPLACE
- **Replacement**: 
  - 4
  - 8
  - continuous
- **Metrics**: Success rate, Node rate, Time (GPU), Time (CPU)

### Encoder Depth Ablation
- **Ablated Part**: Number of stacked encoder layers in the combined multi-head attention encoder (currently fixed to 3 layers)
- **Action**: REPLACE
- **Replacement**: 
  - 1
  - 2
  - 3
  - 4
- **Metrics**: Success rate, Node rate, Time (GPU), Time (CPU)

</div>