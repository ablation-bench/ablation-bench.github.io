<style>
.trajectory-box strong {
  color: #1a1a1a !important;
}
.trajectory-box h3 {
  color: #1a1a1a !important;
}
</style>

# lm-planner/o3-mini/GROOT_2__Weakly_Supervised_Multimodal_Instruction_Following_Agents

<div style="background: linear-gradient(135deg, #e3f2fd 0%, #bbdefb 100%); border-left: 5px solid #2196f3; padding: 20px; margin: 20px 0; border-radius: 8px; box-shadow: 0 2px 8px rgba(0,0,0,0.1); color: #1a1a1a;" class="trajectory-box">
<h2 style="color: #1976d2; margin-top: 0; margin-bottom: 15px; font-size: 1.3em;">ðŸ§  Reasoning Trace</h2>

The first missing ablation study targets the design choice behind the unified multimodal transformer encoder used to process instructions from various modalities (video, text, and returns). Currently, the paper leverages a single encoder to jointly capture intra- and inter-modal relationships to form a shared latent space. However, it remains unclear whether this unified approach is in fact superior to using dedicated, modality-specific encoders followed by a fusion mechanism. Evaluating the two alternatives would provide insight into how joint representation learning impacts the alignment with human intentions and overall task performance. 

The second ablation study examines the impact of the pre-fusion mechanism implemented in the action decoding stage. The paper introduces a lightweight cross-attention module to pool spatial information from the vision tokens using the latent variable as the queryâ€”aimed at reducing sequence length and integrating perceptual inputs more effectively. Removing or modifying this pre-fusion component (e.g., using a simpler concatenation of the latent vector and vision tokens) could reveal its contribution to action prediction accuracy and computational efficiency. Both studies would help to clarify the roles of these novel architectural choices in learning multimodal instruction-following behaviors.
</div>

<div style="background: linear-gradient(135deg, #e8f5e8 0%, #c8e6c9 100%); border-left: 5px solid #4caf50; padding: 20px; margin: 20px 0; border-radius: 8px; box-shadow: 0 2px 8px rgba(0,0,0,0.1); color: #1a1a1a;" class="trajectory-box">
<h2 style="color: #2e7d32; margin-top: 0; margin-bottom: 15px; font-size: 1.3em;">ðŸ“‹ Ablation Plan</h2>

### Ablation on Unified Multimodal Transformer Encoder
- **Ablated Part**: Unified transformer encoder that jointly processes multimodal instructions (video, text, returns) to form a shared latent space
- **Action**: REPLACE
- **Replacement**: 
  - Separate modality-specific encoders with late fusion
  - Distinct encoders per modality followed by cross-modal attention
- **Metrics**: task success rate, instruction following accuracy, latent representation clustering quality

### Ablation on Pre-fusion Mechanism in Action Decoding
- **Ablated Part**: Cross-attention based pre-fusion module that fuses latent variables with vision tokens before action decoding
- **Action**: REMOVE
- **Metrics**: action prediction accuracy, inference computational efficiency, downstream task success rate

</div>