<style>
.trajectory-box strong {
  color: #1a1a1a !important;
}
.trajectory-box h3 {
  color: #1a1a1a !important;
}
</style>

# lm-planner/o3-mini/SMILE__Audio_Visual_Speech_Recognition_with_Siamese_Masked_Interaction_Learning

<div style="background: linear-gradient(135deg, #e3f2fd 0%, #bbdefb 100%); border-left: 5px solid #2196f3; padding: 20px; margin: 20px 0; border-radius: 8px; box-shadow: 0 2px 8px rgba(0,0,0,0.1); color: #1a1a1a;" class="trajectory-box">
<h2 style="color: #1976d2; margin-top: 0; margin-bottom: 15px; font-size: 1.3em;">üß† Reasoning Trace</h2>

The current paper provides extensive ablation studies on several key components such as the effects of adaptive multimodal fusion, different masking strategies and rates, and various Siamese training strategies. However, two critical aspects have not been isolated in the experiments. First, the mix‚Äêattention encoder layer is designed to enable both self-attention within a modality and cross-modal attention between audio and video. There is no ablation study that disables the cross-modal interaction to quantify its contribution. Removing cross-modal attention (i.e. forcing each modality to rely solely on its own features) would reveal how much the complementary information from the other modality actually benefits performance. Second, in the adaptive multimodal fusion module the authors aggregate outputs across all encoder layers using a weighted sum. Although they report improvements with this multi-level fusion, it remains unclear how much benefit is derived from aggregating multiple layers compared to simply using the representation from the final encoder layer only. Replacing the multi-layer fusion with a single-layer (or a simpler average of the last few layers) would help quantify the importance of hierarchical feature integration. Both ablations should be evaluated using the Word Error Rate (WER) metric as in the paper.
</div>

<div style="background: linear-gradient(135deg, #e8f5e8 0%, #c8e6c9 100%); border-left: 5px solid #4caf50; padding: 20px; margin: 20px 0; border-radius: 8px; box-shadow: 0 2px 8px rgba(0,0,0,0.1); color: #1a1a1a;" class="trajectory-box">
<h2 style="color: #2e7d32; margin-top: 0; margin-bottom: 15px; font-size: 1.3em;">üìã Ablation Plan</h2>

### Cross-Modal Interaction Removal Ablation
- **Ablated Part**: Cross-modal interactions within the mix-attention encoder layers where audio and video tokens interact
- **Action**: REMOVE
- **Metrics**: WER

### Single-Layer Fusion Ablation
- **Ablated Part**: Multi-layer weighted fusion in the adaptive multimodal fusion module that aggregates outputs from multiple encoder layers
- **Action**: REPLACE
- **Replacement**: 
  - Use only the final encoder layer output
  - Use simple average of the final two encoder layers
- **Metrics**: WER

</div>