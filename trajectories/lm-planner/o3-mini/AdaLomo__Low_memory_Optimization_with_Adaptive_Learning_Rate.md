<style>
.trajectory-box strong {
  color: #1a1a1a !important;
}
.trajectory-box h3 {
  color: #1a1a1a !important;
}
</style>

# lm-planner/o3-mini/AdaLomo__Low_memory_Optimization_with_Adaptive_Learning_Rate

<div style="background: linear-gradient(135deg, #e3f2fd 0%, #bbdefb 100%); border-left: 5px solid #2196f3; padding: 20px; margin: 20px 0; border-radius: 8px; box-shadow: 0 2px 8px rgba(0,0,0,0.1); color: #1a1a1a;" class="trajectory-box">
<h2 style="color: #1976d2; margin-top: 0; margin-bottom: 15px; font-size: 1.3em;">ðŸ§  Reasoning Trace</h2>

The AdaLomo paper introduces two key innovations: (1) an adaptive per-parameter learning rate realized via a non-negative matrix factorization (NMF) of the second-order moment estimator and (2) a grouped update normalization scheme designed to stabilize convergence, which allows the method to avoid a separate gradient normalization step. While the paper provides ablations on the roles of first- and second-order moments in Adam and evaluates the impact of adding gradient normalization, it does not separately isolate the effect of grouped update normalization. A missing ablation study would remove the grouped update normalization step entirely to assess its direct impact on training stability and task performance (e.g., on MMLU, BBH, GSM8K, HumanEval, AlpacaFarm, and perplexity during further pre-training).

Another important design choice in AdaLomo is the use of non-negative matrix factorization to approximate the second-order moment estimator, which is crucial for reducing the memory footprint. However, the paper does not compare this factorized representation with a full second-order moment estimation (as used in AdamW) or with alternative low-rank approximation strategies. An ablation study replacing the NMF module with a full (or alternative) second-order moment estimator would provide insights into the trade-off between memory efficiency, throughput, and convergence performance.

Based on the impact on convergence stability and overall performance, the removal of grouped update normalization is ranked as the most important missing ablation, followed by the ablation of non-negative matrix factorization.
</div>

<div style="background: linear-gradient(135deg, #e8f5e8 0%, #c8e6c9 100%); border-left: 5px solid #4caf50; padding: 20px; margin: 20px 0; border-radius: 8px; box-shadow: 0 2px 8px rgba(0,0,0,0.1); color: #1a1a1a;" class="trajectory-box">
<h2 style="color: #2e7d32; margin-top: 0; margin-bottom: 15px; font-size: 1.3em;">ðŸ“‹ Ablation Plan</h2>

### Ablation: Remove Grouped Update Normalization
- **Ablated Part**: Grouped update normalization that stabilizes parameter updates in AdaLomo
- **Action**: REMOVE
- **Metrics**: MMLU, BBH, GSM8K, HumanEval, AlpacaFarm, Perplexity

### Ablation: Replace Non-negative Matrix Factorization
- **Ablated Part**: Non-negative matrix factorization used for second-order moment estimation to reduce memory footprint
- **Action**: REPLACE
- **Replacement**: 
  - full second-order moment estimation
  - alternative low-rank approximation methods
- **Metrics**: Memory Consumption, Throughput, MMLU, BBH, GSM8K, HumanEval, AlpacaFarm, Perplexity

</div>